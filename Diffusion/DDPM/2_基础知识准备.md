b站视频 ：https://www.bilibili.com/video/BV1UN411E7hz

---



### 1、概率 - 条件独立

A 和 B 是两个独立事件 $\; \Rightarrow \; P(A|B) = P(A)$，$\quad P(B|A) = P(B)$

$\quad\quad\quad\quad\quad\quad\quad\quad \; \; \;  \Rightarrow P(A, B|C) = P(A|C) P(B|C)$



---



### 2、贝叶斯公式、先验概率、后验概率、似然、证据

$\;$
$叶贝斯公式 ： P(A|B) = \frac{P(B|A)P(A)}{P(B)}$

- 先验概率 (prior)：P(A)
- 后验概率 (posterior) ：P(A|B) 
- 似然 (likelihood)：P(B|A)
- 证据 (evidence)：{P(B)

<img src="https://p.ipic.vip/kb2lkr.png" alt="image-20231003002131405" style="zoom: 45%;" />

<br />

<img src="https://p.ipic.vip/rqeay9.png" alt="img" style="zoom:45%;" />





---



### 3、贝马尔可夫链

马尔可夫链：下一时刻的状态 仅取决于当前时刻的状态，与过去的状态无关

<img src="https://p.ipic.vip/mi13qv.png" alt="image-20231003002419633" style="zoom: 45%;" />

$P(x_t | x_{t-1}, x_{t-2}, ......, x_1, x_0) = P(x_t|x_{t-1})$

正向扩散过程 ：$q(x_0:x_T) = q(x_0) \; q(x_1|x_0) \; q(x_2|x_1) \; ... \; q(x_{T-1}|x_{T-2}) \; q(x_T|x_{T-1})$

逆向扩散过程 ：$p(x_0:x_t) = p(x_{T-1}|x_T) \; p(x_{T-2}|x_{T-1}) \;  ... \; p(x_1|x_2) \; p(x_0|x_1)$



----



### 4、正态分布 / 高斯分布

$\;$
$p(x) = \frac{1}{\sqrt{2 \pi} \sigma}e^{- \frac{(x-\mu)^2}{2\sigma^2}}$

高斯分布的 2个性质: 

$\quad \quad$(1) 如果 $X \sim \mathcal{N}(\mu, \sigma^2)$， 那么 $aX+b \sim \mathcal{N}(a\mu+b, a^2\sigma^2)$ 

$\quad \quad$(2) 两个正态分布相加，其结果也是正态分布 :

$\quad \quad \quad$  $X \sim \mathcal{N}(\mu_1, \sigma_1^2); \;Y \sim \mathcal{N}(\mu_2, \sigma_2^2)， 则 X+Y \sim \mathcal{N}(\mu_1+\mu_2, \sigma_1^2+\sigma_2^2)$ 



----



### 5、重参数化技巧
在含有随机变量的模型中，通常会有<mark>采样</mark>这一个步骤，而采样这个操作是不可导的，没法求出梯度，也就无法通过反向传播来对参数进行优化。

这时，我们就可以通过重参数化技巧，将 简单分布的采样结果 变换到 特定分布中，如此一来则可以对参数进行求导

将原来的采样过程，分解为2步 ： 

（1）引入 服从标准正态分布的随机变量 ： $z \sim \mathcal{N}(0，1)$ 

（2）令 $x = \mu + \sigma z$， 这样 就满足 $X \sim \mathcal{N} (\mu, \sigma^2)$

如此，参数 $\mu 、\sigma$ 就可以求导了



---



### 6、期望

期望 是指随机变量取值的平均值，用来刻画随机变量的集中位置

（1）离散型 随机变量

$\quad \quad$离散型随机变量X 的取值为 $x_1, x_2, x_3, ...., x_n$，对应的概率为 $p_1, p_2, p_3, ...., p_n$

$\quad \quad$则 X 的期望为 ： $E(X) = \sum \limits_{i=1}\limits^{n} x_ip_i$

<img src="https://p.ipic.vip/tu2go8.png" alt="image-20231003003706542" style="zoom:35%;" />

$\quad \quad$ \--------------------------------------------------------------------

$\quad \quad$若离散变量$Y$ 符合函数 $Y=g(X)，g(X)是连续函数$，且 $\sum \limits_{i=1}\limits^{n} g(x_i)p_i$ 绝对收敛，

$\quad \quad$则 离散变量Y 的期望为 ：$E(Y) = \sum \limits_{i=1}\limits^{n} g(x_i)p_i$

（2）连续型随机变量

$\quad \quad$连续型随机变量 $X$ 的概率密度函数为 $f(x)$

$\quad \quad$则 X 的期望为 ： $E(X) = \int_{- \infty}^{\infty} xf(x)dx$

$\quad \quad$ \--------------------------------------------------------------------

$\quad \quad$若随机变量$Y$ 符合函数 $Y=g(x)$，且 $\int_{- \infty}^{\infty} g(x)f(x)dx$ 绝对收敛，

$\quad \quad$则 随机变量Y 的期望为 ：$E(Y) = \int_{- \infty}^{\infty} g(x)f(x)dx$

** 注意 ： 对于连续型随机变量，期望就是积分，满足条件的积分也可以写成期望的形式。这在之后的 公式推导过程中，我们会使用到期望与积分写法的转换



---



### 7、KL散度 、高斯分布的KL散度



KL 散度的作用 ： 用于衡量 2个概率分布 (分布 $p$ 和 分布$q$) 之间的差异

$$\begin{align}
D_{KL}(p||q) 
&= H(p, q) - H(p)  \notag \\
\; \notag \\
&= \int_x p(x) \log \frac{p(x)}{q(x)} dx \notag \\
\; \notag \\
&= E_{x \sim p(x)}[\log \frac{p(x)}{q(x)} \notag] \notag \\
\end{align}$$

其中：

$\quad \quad H(p, q)$ 表示分布$p$ 和 分布$q$ 的交叉熵，

$\quad \quad H(p)$ 表示 分布$p$ 的熵

$\quad \quad$



KL 散度 重要性质 ： 

$\quad \quad$ 1、$D_{KL}(p||q) \geq 0$_

$\quad \quad$ 2、当 分布p 与分布q 完全一样时，$D_{KL}(p||q) = 0$_

$\quad \quad$ 3、对于相同的 分布 $p$ 和 分布$q$， $D_{KL}(p||q)$ 与 $D_{KL}(q||p)$ 计算所得到的值不一样

$\quad \quad \quad \;$ 对于 $D_{KL}(p||q)$，我们一般认为 p(x) 是真实分布，$q(x)$ 是预测分布,_


$\quad \quad \quad \;$ $D_{KL}(p||q)$ 是求 预测分布$q(x)$ 与 真实分布$p(x)$ 之间的差距



---



### 8、极大似然函数



概括描述 ：已知抽取的样本，求概率分布的参数

![image-20231003004146592](https://p.ipic.vip/ywtqlg.png)

似然函数 ： $L(\theta) = \prod \limits_{i=1}^{n} p(x_i|\theta)$ 或 $L(\theta) = \prod \limits_{i=1}^{n} f(x_i|\theta)$

对数似然函数 ： $H(\theta) = log\;L(\theta) = log \; \prod \limits_{i=1}^{n} p(x_i|\theta) =  \sum \limits_{i=1}^{n} log \; p(x_i|\theta)$



为什么要取对数： 

（1）取对数后 求导容易，因为 乘法变加法

（2）保持单调性，最大值的位置不变

（3）概率连乘，（由于计算机精度）乘积可能变0 ； 变加法后，不存在此风险





求解极大似然估计值  $\hat \theta$ :

（1）构造似然函数 $L(\theta)$

（2）对似然函数取对数，得到对数似然函数 $H(\theta) = log\;L(\theta)$ 

（3）对参数求导，然后令导数等于 0 ：  $\frac{\partial H(\theta)}{\partial \theta} =0$
$\quad \quad$(如果是多个参数，比如 $\theta = \{\mu, \sigma\}$，那就分别对参数求偏导，并令偏导数等于0 : $\frac{\partial H(\theta)}{\partial \mu} =0$ ， $\frac{\partial H(\theta)}{\partial \sigma} = 0$)



（4）求解方程，得到 $\theta$ 的极大似然估计值 $\hat \theta$



---



### 9、ELBO

$$\begin{align}
maximize \quad logp_{\theta}(x) 
&= \int_{z} q(z|x) \; logp(x) \;dz \notag \\
\notag \\
&= \int_{z} q(z|x) \; log(\frac{p(z, x)}{p(z|x)}) \;dz \notag \\
\notag \\
&= \int_{z} q(z|x) \; log(\frac{p(z, x)q(z|x)}{p(z|x)q(z|x)}) \;dz \notag \\
\notag \\
&= \int_{z} q(z|x) \; log(\frac{p(z, x)}{q(z|x)}) \;dz  + \int_{z} q(z|x) \; log(\frac{q(z|x)}{p(z|x)}) \;dz\notag \\
\notag \\
&= \int_{z} q(z|x) \; log(\frac{p(z, x)}{q(z|x)}) \;dz  + D_{KL}(q(z|x) ||p(z|x)) \;dz\notag \\
\notag \\
&\geq \int_{z} q(z|x) \; log(\frac{p(z, x)}{q(z|x)}) \;dz \notag \\
\notag \\
&= E_{z \sim q(z|x)}[log(\frac{p(z, x)}{q(z|x)})] \notag \\
\end{align}$$

$$maximize \; logp_{theta}(x) \rightarrow maximize ELBO = E_{z \sim q(z|x)}[logp(\frac{p(z,x)}{z|x})]$$

在 Diffusion 中的应用：上面公式中的 $x$ 换为 $ x_0$， $z$ 换为 $x_1:x_T$

$$maximize \; logp_{theta}(x_0) \rightarrow maximize ELBO = E_{q(x_1:x_T|x_0)}[logp(\frac{p(x_1:x_T,x_0)}{x_1:x_T|x_0})]$$



---



10、一元二次方程

$\;$
一元二次方程标准形式 ： $ax^2 + bx + c = 0$， 其中，$a、b、c \in \mathbb{R}$，且 $a \neq 0$
$\;$

可通过配方法可得到该一元二次方程的方差形式 ： $a(x-\frac{b}{2a})^2 + (\frac{4ac-b^2}{4a})=0$

<br />

<br />

<br />

<br />

<br />



















