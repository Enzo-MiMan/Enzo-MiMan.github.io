b站视频 ： https://www.bilibili.com/video/BV1rh411M7JP

----



## 1、torchsummary.summary  

### 1）函数介绍

作用 ： 可以通过指定输入尺寸，来查看网络每一层的输出尺寸 和 每一层的参数数量。 只需指定输入尺寸即可，不需要实际的输入数据。

```python
torchsummary.summary(model, input_size=(3, 224, 224))
```

参数：

- `model` ：要查看的网络

- `input_size` ：指定网络输入尺寸，可以指定输入的四个维度尺寸（B, C, H, W），也可以只指定输入的三个维度尺寸（C, H, W），如果仅指定三个维度的尺寸（不指定batch_size），那么每一层的输出尺寸 `output shape` 都显示为 -1



### 2）使用举例

```python
from torchsummary import summary
import torchvision.models as models

model = models.alexnet(weights=models.AlexNet_Weights.DEFAULT)
print(summary(model, (3, 224, 224)))
```

输出

```
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 64, 55, 55]          23,296
              ReLU-2           [-1, 64, 55, 55]               0
         MaxPool2d-3           [-1, 64, 27, 27]               0
            Conv2d-4          [-1, 192, 27, 27]         307,392
              ReLU-5          [-1, 192, 27, 27]               0
         MaxPool2d-6          [-1, 192, 13, 13]               0
            Conv2d-7          [-1, 384, 13, 13]         663,936
              ReLU-8          [-1, 384, 13, 13]               0
            Conv2d-9          [-1, 256, 13, 13]         884,992
             ReLU-10          [-1, 256, 13, 13]               0
           Conv2d-11          [-1, 256, 13, 13]         590,080
             ReLU-12          [-1, 256, 13, 13]               0
        MaxPool2d-13            [-1, 256, 6, 6]               0
AdaptiveAvgPool2d-14            [-1, 256, 6, 6]               0
          Dropout-15                 [-1, 9216]               0
           Linear-16                 [-1, 4096]      37,752,832
             ReLU-17                 [-1, 4096]               0
          Dropout-18                 [-1, 4096]               0
           Linear-19                 [-1, 4096]      16,781,312
             ReLU-20                 [-1, 4096]               0
           Linear-21                 [-1, 1000]       4,097,000
================================================================
Total params: 61,100,840
Trainable params: 61,100,840
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.57
Forward/backward pass size (MB): 8.38
Params size (MB): 233.08
Estimated Total Size (MB): 242.03
----------------------------------------------------------------
None
```







----



## 2、TensorBoardX

使用 `TensorBoardX` 查看网络结构，分为三个步骤：

1）实例化一个 `SummaryWriter` 对象

2）让 `SummaryWriter ` 对象调用 `add_graph` 方法来获取模型结构

3）打开浏览器查看 模型的可视化起结构



### 1）实例化 SummaryWriter

实例化 `SummaryWriter` 对象的时候，有三种指定参数的方式

```python
from tensorboardX import SummaryWriter

# 提供一个路径，将使用该路径来保存日志
writer1 = SummaryWriter(log_dir='./runs')

# 无参数，默认使用 runs/日期时间 路径来保存日志，比如：'runs/Aug20-17-20-33'
writer2 = SummaryWriter()

# 提供一个 comment 参数，将使用 runs/日期时间-comment 路径来保存日志，比如： 'runs/Aug20-17-20-33-resnet'
writer3 = SummaryWriter(comment='_resnet')

```



### 2）add_graph 函数介绍

```python
add_graph(model, input_to_model=None, verbose=False, **kwargs)
```

参数

- `model` : 待可视化的网络模型
- `input_to_model` : 待输入神经网络的变量或一组变量



### 3）浏览器查看结果

在终端 cd 到 logs目录所在的同级目录，输入如下命令

```
tensorboard --logdir ./logs --port 6006
```

注意：路径不要加双引号

在浏览器窗口输入地址：http://localhost:6006/   ， 查看模型网络结构



### 4）使用举例

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
from tensorboardX import SummaryWriter

class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)
        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)
        self.conv2_drop = nn.Dropout2d()
        self.fc1 = nn.Linear(320, 50)
        self.fc2 = nn.Linear(50, 10)
        self.bn = nn.BatchNorm2d(20)
        
    def forward(self, x):
        x = F.max_pool2d(self.conv1(x), 2)
        x = F.relu(x) + F.relu(x)
        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))
        x = self.bn(x)
        x = x.view(-1, 320)
        x = F.relu(self.fc1(x))
        x = F.dropout(x, training=self.training)
        x = self.fc2(x)
        x = F.softmax(x, dim=1)
        return x
    

input = torch.rand(32, 1, 28, 28)
    
model = Net()
with SummaryWriter(log_dir='logs', comment='Net') as w:
    w.add_graph(model, input)
```

![在这里插入图片描述](https://p.ipic.vip/r4y1sp.png)







----



## 3、Netron

两种使用方式： 1、使用在线版； 2、下载本地版

### 1）使用在线版

浏览器访问：[https://netron.app/](https://netron.app/)
点击 “Open Model” 按钮，选择要可视化的模型文件即可

<img src="https://p.ipic.vip/yp509b.png" alt="img" style="zoom:25%;" />



### 2）下载本地版

终端进行安装： `pip install netron`
安装完成后，在脚本中 调用包 `import netron`
运行程序  `netron.start("model.onnx")`， 会自动打开浏览器进行可视化 （最后有例子）



### 3）支持的网络框架 和 模型文件类型

<img src="https://p.ipic.vip/qph2mn.png" alt="image-20231002170425326" style="zoom: 49%;" />



我习惯用 pytorch，但是 netron 对 pytorch 的 `.pt` 和 `.pth` 文件不是很友好，所以，我都是先转换为 onnx 格式，再进行可视化，下面举例。

另外，netron 可以直接可视化 yolo  （DarkNet 框架）的 .cfg文件，非常方便





### 4）使用举例

一般情况下，netron 只展示最初的输入尺寸 和 最后的输出尺寸，中间层的尺寸都是不展示的（如下）。

<img src="https://p.ipic.vip/vrjo84.png" alt="img" style="zoom:33%;" />



可以同过 `onnx.save(onnx.shape_inference.infer_shapes(onnx.load("model.onnx")), "model.onnx")` 进行处理。这样中间的每一层的输入输出就都会推理出 并可视化出来了。

```python
import torch
import torch.nn as nn
import netron
import onnx
from onnx import shape_inference


class My_Net(nn.Module):
    def __init__(self):
        super(My_Net, self).__init__()
        self.layer1 = nn.Sequential(
            nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False),
            nn.BatchNorm2d(16),
            nn.LeakyReLU(),
        )

        self.layer2 = nn.Sequential(
            nn.Conv2d(16, 32, kernel_size=1, bias=False),
            nn.BatchNorm2d(32),
            nn.LeakyReLU(),
        )

    def forward(self, x):
        x = self.layer1(x)
        x = self.layer2(x)
        return x


net = My_Net()
img = torch.rand((1, 3, 224, 224))
torch.onnx.export(model=net, args=img, f='model.onnx', input_names=['image'], output_names=['feature_map'])
onnx.save(onnx.shape_inference.infer_shapes(onnx.load("model.onnx")), "model.onnx")
netron.start("model.onnx")
```



<img src="https://p.ipic.vip/izi7zp.png" alt="img" style="zoom:50%;" />



























